Prompt Engineering Models may be sensitive to the choice of prompt (especially without fine- tuning), and a number of works attempt to optimize the prompt for the task at hand (Jiang et al., 2020; Shin et al., 2020). Recently, a number of works have also proposed generalizing prompts to include task-specific parameters and embeddings, typically learnt via gradient descent while keeping parts or all of the modelâ€™s parameters frozen (Houlsby et al., 2019; Liu et al., 2021b; Zhong et al., 2021; Qin and Eisner, 2021; Li and Liang, 2021; Lester et al., 2021; Logan et al., 2021). While these tech- niques can improve results for frozen models, they generally do not outperform fine-tuning the whole model (Lester et al., 2021), hence we choose to fo- cus on full-model finetuning with standard prompts in our experiments.

From [[../../../../Explorance/Research/Papers/A Few More Examples May Be Worth Billions of Parameters]]
