
Few-Shot Learning Analysis Closest to our contribution are works placing an emphasis on the analysis of few-shot model behaviour, rather than focusing on schemes to improve performance. Le Scao and Rush (2021) quantify the benefit of prompting in few-shot learning, and Perez et al. (2021) critically discuss the difficulty of model selection and very low dataset sizes in few-shot learning. Our work is complementary, exploring the relationship between scale, dataset size, and task open-endedness.

From [[A Few More Examples May Be Worth Billions of Parameters]]
