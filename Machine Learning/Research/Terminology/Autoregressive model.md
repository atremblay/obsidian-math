The Autoregressive Model, or AR model for short, relies only on past period values to predict current ones. 

For example, RNN trained on predicting the next word by only considering past words.

Most large-scale models are trained in an auto-regressive way, but [[BERT]] shows that such models demonstrate poorer performance with traditional fine-tuning when adapting to downstream language understanding tasks.
