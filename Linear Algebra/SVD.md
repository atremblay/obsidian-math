The diagonalization theorems in Sections 5.3 and 7.1 play a part in many interesting applications. Unfortunately, as we know, not all matrices can be factored as $A=PDP^{-1}$  with $D$ diagonal. However, a factorization $A=QDP^{-1}$ is possible for any $m \times n$  matrix $A$! A special factorization of this type, called the singular value decomposition, is one of the most useful matrix factorizations in applied linear algebra. The singular value decomposition is based on the following property of the ordinary diagonalization that can be imitated for rectangular matrices: The absolute values of the  eigenvalues of a symmetric matrix $A$ measure the amounts that $A$ stretches or shrinks certain vectors (the eigenvectors). If $A\mathbf{x} = \lambda \mathbf{x}$ and $\lVert \mathbf{x} \lVert=1$, then  
$$
\lVert A\mathbf{x}\lVert = \lVert \lambda \mathbf{x} \lVert = \lvert \lambda \lvert \lVert \mathbf{x} \lVert = \lvert \lambda \lvert \tag{1} \label{eq7.4 1}
$$
If $\lambda_1$ the eigenvalue with the greatest magnitude, then a corresponding unit eigenvector $\mathbf{v}_1$ identifies a direction in which the stretching effect of $A$ is greatest. That is, the  length of $A\mathbf{x}$ is maximized when $\mathbf{x}=\mathbf{v}_1$, and $A\mathbf{v}_1=\lvert \lambda_1 \lvert$ by $\eqref{eq7.4 1}$. This description of $A\mathbf{v}_1$and $\lvert \lambda_1 \lvert$ has an analogue for rectangular matrices that will lead to the singular value  decomposition.
